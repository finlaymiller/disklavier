{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from itertools import product\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "BUILD_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545952 rows in file\n",
      "loaded embeddings: (545952, 1)\n"
     ]
    }
   ],
   "source": [
    "p_h5 = \"data/clamp_embeddings.h5\"\n",
    "if BUILD_DATASET:\n",
    "    import redis\n",
    "    r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)\n",
    "    n_rows = 0\n",
    "    keys: list[str] = r.keys('files:*') # type: ignore\n",
    "    keys.sort()\n",
    "    embeddings = torch.empty((len(keys), 768), dtype=torch.float32, device='cuda')\n",
    "    for i, key in track(enumerate(keys), \"downloading embeddings\"): # type: ignore\n",
    "        embeddings[i] = torch.Tensor(r.json().get(key, \"$.clamp\")[0]) # type: ignore\n",
    "    print(embeddings.shape)\n",
    "else:\n",
    "    # verify hdf5 file\n",
    "    with h5py.File(p_h5, \"r\") as hdf:\n",
    "        print(f\"{len(hdf.keys())} rows in file\")\n",
    "        embeddings = pd.DataFrame(index=list(hdf.keys()), columns=[\"embedding\"])\n",
    "        # Iterate over all items in the HDF5 file\n",
    "        nk = 0\n",
    "        for key in hdf.keys():\n",
    "            # Get the dataset associated with the key\n",
    "            dataset = hdf[key]\n",
    "            # Print the key and its corresponding value\n",
    "            if key in embeddings.index:  # Check if the key exists\n",
    "                embeddings.loc[key, \"embedding\"] = hdf[key][:]\n",
    "            else:\n",
    "                print(f\"Key '{key}' not found in embeddings.\")\n",
    "        print(f\"loaded embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings in MB: 1720.24 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of embeddings in MB: {embeddings.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 545952 rows to 'data/clamp_embeddings.h5' ['20231220-080-01_0000-0005_t00s00', '20231220-080-01_0000-0005_t00s01', '20231220-080-01_0000-0005_t00s02']\n"
     ]
    }
   ],
   "source": [
    "# os.remove(p_h5)\n",
    "with h5py.File(p_h5, 'w') as hdf:\n",
    "    for i, (k, e) in enumerate(zip(keys, embeddings)):\n",
    "        hdf.create_dataset(k.split(':')[-1], data=e.cpu().numpy())\n",
    "        keys[i] = keys[i].split(':')[-1]\n",
    "print(f\"wrote {len(keys)} rows to '{p_h5}'\\n\", keys[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(filename: str) -> torch.Tensor:\n",
    "\treturn embeddings[keys.index(filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240511-088-02_0119-0125_t11s07',\n",
       " '20240305-050-04_0076-0086_t02s03',\n",
       " '20231220-080-04_0029-0035_t11s02']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prompt dataset\n",
    "p_test = \"../data/datasets/test/dataset samples\"\n",
    "transformations = [f\"t{t:02d}s{s:02d}\" for t, s in product(range(12), range(8))]\n",
    "q_files = [f\"{f[:-4]}_{rng.choice(transformations)}\" for f in os.listdir(p_test)]\n",
    "q_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prompt embeddings\n",
    "q_embeddings = [get_embedding(key) for key in q_files]\n",
    "q_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240511-088-02_0119-0125_t11s07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simple': [['20240511-088-02_0119-0125_t11s07', 1.0000001192092896],\n",
       "  ['20240511-088-02_0119-0125_t08s07', 0.9173212647438049],\n",
       "  ['20240511-088-03_0021-0027_t06s06', 0.9104568958282471],\n",
       "  ['20240511-088-03_0021-0027_t03s05', 0.9012600779533386],\n",
       "  ['20240511-088-03_0021-0027_t09s04', 0.8920480012893677],\n",
       "  ['20231227-080-03_0233-0239_t11s03', 0.31363505125045776],\n",
       "  ['20240123-070-07_0425-0431_t06s03', 0.31282979249954224],\n",
       "  ['20240123-070-07_0438-0445_t06s00', 0.3121066391468048],\n",
       "  ['20240123-070-07_0438-0445_t00s04', 0.30916541814804077],\n",
       "  ['20240123-070-07_0438-0445_t08s05', 0.2884775698184967]],\n",
       " 'cplx': [['20240511-088-03_0021-0027_t06s06', 0.9104568958282471],\n",
       "  ['20240124-064-02_0449-0457_t10s00', 0.8811522126197815],\n",
       "  ['20240429-068-03_0070-0077_t10s04', 0.8779870271682739],\n",
       "  ['20240312-080-05_0035-0041_t00s05', 0.8743062019348145],\n",
       "  ['20240123-070-03_0774-0781_t08s03', 0.8720983266830444],\n",
       "  ['20240312-080-03_0005-0011_t06s00', 0.3329693675041199],\n",
       "  ['20240227-076-05_0025-0031_t09s06', 0.3187159597873688],\n",
       "  ['20240213-100-03_0143-0148_t04s00', 0.31780746579170227],\n",
       "  ['20231227-080-03_0233-0239_t11s03', 0.31363505125045776],\n",
       "  ['20240123-070-07_0438-0445_t08s05', 0.2884775698184967]]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find best and worst n matches for prompts\n",
    "n_matches = 5\n",
    "matches = {}\n",
    "for i, query in enumerate(q_embeddings):\n",
    "    similarities = torch.matmul(embeddings, query) / (torch.norm(embeddings, dim=1) * torch.norm(query))\n",
    "    sim_cpu = similarities.cpu().numpy()\n",
    "    matches[q_files[i]] = {}\n",
    "\n",
    "    # no regard for different segments\n",
    "    matches[q_files[i]]['simple'] = []\n",
    "    for j in np.argsort(-sim_cpu)[:n_matches]: # indices of best matches\n",
    "        matches[q_files[i]]['simple'].append([keys[j], float(sim_cpu[j])])\n",
    "    for j in np.argsort(-sim_cpu)[-n_matches:]: # indices of worst matches\n",
    "        matches[q_files[i]]['simple'].append([keys[j], float(sim_cpu[j])])\n",
    "\n",
    "    # force different segments and unique each time\n",
    "    matches[q_files[i]]['cplx'] = []\n",
    "    q_track = q_files[i].split('_')[0]\n",
    "    n_found = 0\n",
    "    for k in np.argsort(-sim_cpu):\n",
    "        match_track = keys[k].split('_')[0]\n",
    "        added_matches = [m[0].split('_')[0] for m in matches[q_files[i]]['cplx']]\n",
    "        if match_track == q_track or match_track in added_matches:\n",
    "            continue\n",
    "        matches[q_files[i]]['cplx'].append([keys[k], float(sim_cpu[k])])\n",
    "        n_found += 1\n",
    "        if n_found >= n_matches:\n",
    "            break\n",
    "    n_found = 0\n",
    "    for k in reversed(np.argsort(-sim_cpu)):\n",
    "        match_track = keys[k].split('_')[0]\n",
    "        added_matches = [m[0].split('_')[0] for m in matches[q_files[i]]['cplx']]\n",
    "        if match_track == q_track or match_track in added_matches:\n",
    "            continue\n",
    "        matches[q_files[i]]['cplx'].append([keys[k], float(sim_cpu[k])])\n",
    "        n_found += 1\n",
    "        if n_found >= n_matches:\n",
    "            break\n",
    "\n",
    "    # reverse order of worst complex matches due to search direction\n",
    "    matches[q_files[i]]['cplx'][-n_matches:] = reversed(matches[q_files[i]]['cplx'][-n_matches:])\n",
    "    \n",
    "print(q_files[0])\n",
    "matches[q_files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/matches.json', 'w') as f:\n",
    "    json.dump(matches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240511-088-02_0119-0125_t11s07',\n",
       " '20240511-088-02_0119-0125_t08s07',\n",
       " '20240511-088-03_0021-0027_t06s06',\n",
       " '20240511-088-03_0021-0027_t03s05',\n",
       " '20240511-088-03_0021-0027_t09s04',\n",
       " '20240511-088-03_0065-0070_t01s06',\n",
       " '20240511-088-02_0076-0081_t09s07',\n",
       " '20240124-064-02_0449-0457_t10s00',\n",
       " '20240429-068-03_0070-0077_t10s04',\n",
       " '20240511-088-03_0000-0005_t00s05',\n",
       " '20240511-088-02_0119-0125_t06s01',\n",
       " '20240429-068-03_0197-0204_t07s01',\n",
       " '20240124-064-02_0607-0614_t09s07',\n",
       " '20240124-064-02_0637-0644_t08s03',\n",
       " '20240511-088-02_0119-0125_t08s01',\n",
       " '20240312-080-05_0035-0041_t00s05',\n",
       " '20240312-080-05_0041-0047_t01s05',\n",
       " '20240123-070-03_0774-0781_t08s03',\n",
       " '20240124-064-02_0569-0577_t07s04',\n",
       " '20240124-064-02_0622-0629_t06s04']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = q_files.index(\"20240511-088-02_0119-0125_t11s07\")\n",
    "query = q_embeddings[i]\n",
    "similarities = torch.matmul(embeddings, query) / (torch.norm(embeddings, dim=1) * torch.norm(query))\n",
    "sim_cpu = similarities.cpu().numpy()\n",
    "[keys[k]  for k in np.argsort(-sim_cpu)[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t20240511-088-02_0119-0125_t11s07\n",
      "\tsimple\n",
      "\t\t20240511-088-02_0119-0125_t11s07\t1.0000001192092896\n",
      "\t\t20240511-088-02_0119-0125_t08s07\t0.9173212647438049\n",
      "\t\t20240511-088-03_0021-0027_t06s06\t0.9104568958282471\n",
      "\t\t20240123-070-07_0438-0445_t06s00\t0.3121066391468048\n",
      "\t\t20240123-070-07_0438-0445_t00s04\t0.30916541814804077\n",
      "\t\t20240123-070-07_0438-0445_t08s05\t0.2884775698184967\n",
      "\tcplx\n",
      "\t\t20240511-088-03_0021-0027_t06s06\t0.9104568958282471\n",
      "\t\t20240511-088-03_0065-0070_t01s06\t0.8881725072860718\n",
      "\t\t20240511-088-02_0076-0081_t09s07\t0.8876845836639404\n",
      "\t\t20231227-080-03_0233-0239_t11s03\t0.31363505125045776\n",
      "\t\t20240123-070-07_0425-0431_t06s03\t0.31282979249954224\n",
      "\t\t20240123-070-07_0438-0445_t08s05\t0.2884775698184967\n"
     ]
    }
   ],
   "source": [
    "with open('data/matches.json', 'r') as f:\n",
    "    json_matches = json.load(f)\n",
    "index = 0\n",
    "for i, (q, ms) in enumerate(json_matches.items()):\n",
    "    if i == index:\n",
    "        print(f\"{i}\\t{q}\")\n",
    "        for mode, matches in ms.items():\n",
    "            print(f\"\\t{mode}\")\n",
    "            for f, s in matches:\n",
    "                print(f\"\\t\\t{f}\\t{s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
