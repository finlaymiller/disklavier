{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich.progress import track\n",
    "from scipy.spatial.distance import cosine\n",
    "from itertools import product\n",
    "from rich.progress import track\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['embeddings', 'filenames']>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unable to synchronously open object (invalid dataset size, likely file corruption)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/scratch/sageev-midi/20250320/specdiff.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hdf:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(hdf\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mhdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(hdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilenames\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(hdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/midi-ml/lib/python3.12/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unable to synchronously open object (invalid dataset size, likely file corruption)'"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"/media/scratch/sageev-midi/20250320/specdiff.h5\", \"r\") as hdf:\n",
    "    print(hdf.keys())\n",
    "    print(hdf[\"embeddings\"])\n",
    "    print(str(hdf[\"filenames\"][0], \"utf-8\"))\n",
    "    print(hdf[\"embeddings\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e69aec00ff4e4d9ac22de827c5439d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# p_h5 = \"../data/tables/20250110/specdiff.h5\"\n",
    "# with h5py.File(p_h5, \"r\") as hdf_in:\n",
    "#     with h5py.File(\"../data/tables/20250110/specdiff_new.h5\", \"w\") as hdf_out:\n",
    "#         new_names = hdf_out.create_dataset(\n",
    "#             \"filenames\",\n",
    "#             (len(hdf_in[\"filenames\"]), 1),\n",
    "#             dtype=h5py.string_dtype(encoding=\"utf-8\"),\n",
    "#             fillvalue=\"\",\n",
    "#         )\n",
    "#         embeddings = hdf_out.create_dataset(\n",
    "#             \"embeddings\", (len(hdf_in[\"embeddings\"]), 768)\n",
    "#         )\n",
    "\n",
    "#         for i, name in track(enumerate(hdf_in[\"filenames\"])):\n",
    "#             new_names[i] = str(name[0][:-7], \"utf-8\")\n",
    "#             embeddings[i] = hdf_in[\"embeddings\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'20231220-080-01_0000-0005_t00s00']\n",
      " [b'20231220-080-01_0000-0005_t00s01']\n",
      " [b'20231220-080-01_0000-0005_t00s02']\n",
      " [b'20231220-080-01_0000-0005_t00s03']\n",
      " [b'20231220-080-01_0000-0005_t00s04']]\n",
      "[[0.         0.         0.18383147 0.         0.         0.\n",
      "  0.         0.81616855 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.18383147 0.         0.         0.\n",
      "  0.         0.81616855 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.18383147 0.         0.         0.\n",
      "  0.         0.81616855 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.18383147 0.         0.         0.\n",
      "  0.         0.81616855 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.18383147 0.         0.         0.\n",
      "  0.         0.81616855 0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"../data/tables/20250110/specdiff.h5\", \"r\") as hdf:\n",
    "    print(hdf[\"filenames\"][:5])\n",
    "    print(hdf[\"embeddings\"][:5])\n",
    "with h5py.File(\"../data/tables/20250110/pitch_histogram.h5\", \"r\") as hdf:\n",
    "    print(hdf[\"filenames\"][:5])\n",
    "    print(hdf[\"histograms\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 datasets in file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20231220-080-01_0000-0005_t00s00</th>\n",
       "      <td>[-0.053769037, -0.13694727, 0.061716847, 0.084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231220-080-01_0000-0005_t00s01</th>\n",
       "      <td>[-0.038331196, -0.13422038, 0.0947322, 0.09812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231220-080-01_0000-0005_t00s02</th>\n",
       "      <td>[-0.05655879, -0.15524468, 0.057764757, 0.0674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231220-080-01_0000-0005_t00s03</th>\n",
       "      <td>[-0.043163337, -0.13563132, 0.09134518, 0.0746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231220-080-01_0000-0005_t00s04</th>\n",
       "      <td>[-0.057311468, -0.15267283, 0.07441097, 0.0672...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         embeddings\n",
       "20231220-080-01_0000-0005_t00s00  [-0.053769037, -0.13694727, 0.061716847, 0.084...\n",
       "20231220-080-01_0000-0005_t00s01  [-0.038331196, -0.13422038, 0.0947322, 0.09812...\n",
       "20231220-080-01_0000-0005_t00s02  [-0.05655879, -0.15524468, 0.057764757, 0.0674...\n",
       "20231220-080-01_0000-0005_t00s03  [-0.043163337, -0.13563132, 0.09134518, 0.0746...\n",
       "20231220-080-01_0000-0005_t00s04  [-0.057311468, -0.15267283, 0.07441097, 0.0672..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify hdf5 file\n",
    "p_h5 = \"../data/tables/20250110/specdiff.h5\"\n",
    "with h5py.File(p_h5, \"r\") as hdf:\n",
    "    print(f\"{len(hdf.keys())} datasets in file\")\n",
    "    new_names = hdf.create_dataset(\"filenames\")\n",
    "    df = pd.DataFrame(\n",
    "        list([e] for e in hdf[\"embeddings\"]),\n",
    "        index=[str(name[0][:-7], \"utf-8\") for name in hdf[\"filenames\"]],\n",
    "        columns=[\"embeddings\"],\n",
    "    )\n",
    "df.head()\n",
    "# df.to_hdf(\"../data/tables/20250110/specdiff_new.h5\", key=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt dataset\n",
    "p_test = \"../data/datasets/test/dataset samples\"\n",
    "transformations = [f\"t{t:02d}s{s:02d}\" for t, s in product(range(12), range(8))]\n",
    "q_files = [f\"{f[:-4]}_{rng.choice(transformations)}\" for f in os.listdir(p_test)]\n",
    "q_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompt embeddings\n",
    "q_embeddings = [embedding_dataset[key] for key in q_files]\n",
    "q_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dataset.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best and worst n matches for prompts\n",
    "n_matches = 3\n",
    "indices = []  # To store the indices of the best and worst matches\n",
    "for q_emb in q_embeddings:\n",
    "    similarities = []\n",
    "    for idx, dataset in enumerate(embedding_dataset.values()):\n",
    "        sim = 1 - cosine(q_emb, dataset)\n",
    "        similarities.append((sim, idx))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)  # Highest first\n",
    "    best_indices = [idx for _, idx in similarities[:n_matches]]  # Top 3\n",
    "    worst_indices = [idx for _, idx in similarities[-n_matches:]]  # Bottom 3\n",
    "\n",
    "    indices.append((best_indices, worst_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dataset.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
