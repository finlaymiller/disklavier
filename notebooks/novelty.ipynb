{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# novelty\n",
    "\n",
    "testing out how i can calculate the novelty curve of a midi file and add a message with the novelty value at each beat of the midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pretty_midi\n",
    "from midi_player import MIDIPlayer\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy.typing as npt\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "from midi_player.stylers import dark\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions\n",
    "from `utils/novelty.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ssm_and_novelty(\n",
    "    features, L=1, filter_length=41, down_sampling=10, hop=1024, sr=100\n",
    "):\n",
    "    features, _ = smooth_downsample_feature_sequence(\n",
    "        features, sr / hop, filter_length, down_sampling\n",
    "    )\n",
    "\n",
    "    print(features.shape)\n",
    "\n",
    "    ssm = np.dot(np.transpose(features), features)\n",
    "    novelty = compute_novelty_ssm(ssm, L, exclude=True)\n",
    "\n",
    "    return ssm, novelty\n",
    "\n",
    "\n",
    "def get_peaks(data: npt.NDArray, Thalf=10, tau=1.35, distance=7):\n",
    "    \"\"\"from SSMNet\"\"\"\n",
    "\n",
    "    nb_frame = len(data)\n",
    "\n",
    "    # compute peak to mean ratio\n",
    "    peak_to_mean_v = np.zeros((nb_frame))\n",
    "    for nu in range(0, nb_frame):\n",
    "        sss = max(0, nu - Thalf)\n",
    "        eee = min(nu + Thalf + 1, nb_frame)\n",
    "        local_mean = np.sum(data[sss:eee]) / (eee - sss)\n",
    "        peak_to_mean_v[nu] = data[nu] / local_mean if local_mean != 0 else 0\n",
    "\n",
    "    # find peaks\n",
    "    peaks, _ = signal.find_peaks(peak_to_mean_v, distance=distance)\n",
    "\n",
    "    # above threshold tau\n",
    "    above_threshold = np.where(peak_to_mean_v[peaks] >= tau)[0]\n",
    "\n",
    "    return peaks[above_threshold]\n",
    "\n",
    "\n",
    "def get_boundaries(\n",
    "    novelty: npt.NDArray[np.float64],\n",
    "    time_sec_v: npt.NDArray[np.float64],\n",
    "    peak_settings: Dict = {},\n",
    ") -> Tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]:\n",
    "    \"\"\"Estimate the boundaries using the novelty curve.\n",
    "\n",
    "    Args:\n",
    "        novelty: the novelty curve\n",
    "        time_sec_v: an array of seconds indicators\n",
    "        peak_settings: custom settings for peak detection\n",
    "\n",
    "    Returns:\n",
    "        boundary_sec_v: boundary indices in seconds\n",
    "        boundary_frame_v: boundary indices in frames\n",
    "    \"\"\"\n",
    "    if len(peak_settings.values()) > 0:\n",
    "        boundary_frame_v = get_peaks(\n",
    "            novelty,\n",
    "            peak_settings[\"Thalf\"],\n",
    "            peak_settings[\"tau\"],\n",
    "            peak_settings[\"distance\"],\n",
    "        )\n",
    "    else:\n",
    "        boundary_frame_v = get_peaks(\n",
    "            novelty,\n",
    "        )\n",
    "    boundary_sec_v = time_sec_v[boundary_frame_v]\n",
    "\n",
    "    # add start and end-time\n",
    "    boundary_sec_v = np.concatenate(\n",
    "        (0 * np.ones(1), boundary_sec_v, time_sec_v[-1] * np.ones(1))\n",
    "    )\n",
    "\n",
    "    # to be sure there is not twice zero\n",
    "    boundary_sec_v = np.array(sorted([aaa for aaa in set(boundary_sec_v)]))\n",
    "\n",
    "    return boundary_sec_v, boundary_frame_v\n",
    "\n",
    "\n",
    "def compute_novelty_ssm(\n",
    "    S, kernel=None, L=10, var=0.5, exclude=False\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    \"\"\"Compute novelty function from SSM [FMP, Section 4.4.1]\n",
    "\n",
    "    Notebook: C4/C4S4_NoveltySegmentation.ipynb\n",
    "\n",
    "    Args:\n",
    "        S (np.ndarray): SSM\n",
    "        kernel (np.ndarray): Checkerboard kernel (if kernel==None, it will be computed) (Default value = None)\n",
    "        L (int): Parameter specifying the kernel size M=2*L+1 (Default value = 10)\n",
    "        var (float): Variance parameter determing the tapering (epsilon) (Default value = 0.5)\n",
    "        exclude (bool): Sets the first L and last L values of novelty function to zero (Default value = False)\n",
    "\n",
    "    Returns:\n",
    "        nov (np.ndarray): Novelty function\n",
    "    \"\"\"\n",
    "    if kernel is None:\n",
    "        kernel = compute_kernel_checkerboard_gaussian(L=L, var=var)\n",
    "    N = S.shape[0]\n",
    "    M = 2 * L + 1\n",
    "    nov = np.zeros(N)\n",
    "    # np.pad does not work with numba/jit\n",
    "    S_padded = np.pad(S, L, mode=\"constant\")\n",
    "\n",
    "    for n in range(N):\n",
    "        # Does not work with numba/jit\n",
    "        nov[n] = np.sum(S_padded[n : n + M, n : n + M] * kernel)\n",
    "    if exclude:\n",
    "        right = np.min([L, N])\n",
    "        left = np.max([0, N - L])\n",
    "        nov[0:right] = 0\n",
    "        nov[left:N] = 0\n",
    "\n",
    "    return nov\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_kernel_checkerboard_gaussian(\n",
    "    L, var=1.0, normalize=True\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    \"\"\"Compute Guassian-like checkerboard kernel [FMP, Section 4.4.1].\n",
    "    See also: https://scipython.com/blog/visualizing-the-bivariate-gaussian-distribution/\n",
    "\n",
    "    Notebook: C4/C4S4_NoveltySegmentation.ipynb\n",
    "\n",
    "    Args:\n",
    "        L (int): Parameter specifying the kernel size M=2*L+1\n",
    "        var (float): Variance parameter determing the tapering (epsilon) (Default value = 1.0)\n",
    "        normalize (bool): Normalize kernel (Default value = True)\n",
    "\n",
    "    Returns:\n",
    "        kernel (np.ndarray): Kernel matrix of size M x M\n",
    "    \"\"\"\n",
    "    taper = np.sqrt(1 / 2) / (L * var)\n",
    "    axis = np.arange(-L, L + 1)\n",
    "    gaussian1D = np.exp(-(taper**2) * (axis**2))\n",
    "    gaussian2D = np.outer(gaussian1D, gaussian1D)\n",
    "    kernel_box = np.outer(np.sign(axis), np.sign(axis))\n",
    "    kernel = kernel_box * gaussian2D\n",
    "\n",
    "    if normalize:\n",
    "        kernel = kernel / np.sum(np.abs(kernel))\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def smooth_downsample_feature_sequence(\n",
    "    X, Fs, filt_len=41, down_sampling=10, w_type=\"boxcar\"\n",
    "):\n",
    "    \"\"\"Smoothes and downsamples a feature sequence. Smoothing is achieved by convolution with a filter kernel\n",
    "\n",
    "    Notebook: C3/C3S1_FeatureSmoothing.ipynb\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Feature sequence\n",
    "        Fs (scalar): Frame rate of ``X``\n",
    "        filt_len (int): Length of smoothing filter (Default value = 41)\n",
    "        down_sampling (int): Downsampling factor (Default value = 10)\n",
    "        w_type (str): Window type of smoothing filter (Default value = 'boxcar')\n",
    "\n",
    "    Returns:\n",
    "        X_smooth (np.ndarray): Smoothed and downsampled feature sequence\n",
    "        Fs_feature (scalar): Frame rate of ``X_smooth``\n",
    "    \"\"\"\n",
    "    filt_kernel = np.expand_dims(signal.get_window(w_type, filt_len), axis=0)\n",
    "    X_smooth = signal.convolve(X, filt_kernel, mode=\"same\") / filt_len\n",
    "    X_smooth = X_smooth[:, ::down_sampling]\n",
    "    Fs_feature = Fs / down_sampling\n",
    "    return X_smooth, Fs_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIPlayer(pretty_midi.PrettyMIDI(test_file), 300, styler=dark)\n",
    "test_file = \"files/20231220-080-01.mid\"\n",
    "piano_roll = pretty_midi.PrettyMIDI(test_file).get_piano_roll()\n",
    "tempo = 80\n",
    "beat_len = 60 / tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sssm, n_smoothed = gen_ssm_and_novelty(\n",
    "    piano_roll, filter_length=1, down_sampling=1\n",
    ")\n",
    "boundary = get_boundaries(\n",
    "    n_smoothed, np.array(range(n_smoothed.shape[0]))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
